{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"J7Fb9ihyr8vS"},"outputs":[],"source":["import numpy as np \n","import pandas as pd\n","from scipy.stats import skew\n","from scipy.signal import find_peaks\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import mean_absolute_error, roc_auc_score\n","from itertools import chain\n","from collections import Counter\n","import itertools\n","import pickle\n","import os"]},{"cell_type":"markdown","metadata":{"id":"AuMYqFGBrGv_"},"source":["##**Functions**"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"y2Ghw5QKsl6H"},"outputs":[],"source":["def extract_list_feats(list_name: str, data, features_name: list, base=None):\n","    \"\"\"\n","    Extract Features from vector.\n","    :param list_name: Vector to extract features from.\n","    :param data: Dataset to extract features from.\n","    :param features_name: Feature list to add new feature names to.\n","    :param base: Disable the use of features.\n","    :return: Data with features, updated feature name list.\n","    \"\"\"\n","\n","    if base is None:\n","        base = DEFAULT_TRUE_LIST\n","\n","    data[f'max_{list_name}'] = data[list_name].apply(np.max)\n","    if base[0]:\n","        features_name += [f'max_{list_name}']\n","\n","    data[f'min_{list_name}'] = data[list_name].apply(np.min)\n","    if base[1]:\n","        features_name += [f'min_{list_name}']\n","\n","    data[f'mean_{list_name}'] = data[list_name].apply(np.mean)\n","    if base[2]:\n","        features_name += [f'mean_{list_name}']\n","\n","    data[f'median_{list_name}'] = data[list_name].apply(np.median)\n","    if base[3]:\n","        features_name += [f'median_{list_name}']\n","\n","    data[f'std_{list_name}'] = data[list_name].apply(np.std)\n","    if base[4]:\n","        features_name += [f'std_{list_name}']\n","\n","    data[f'skew_{list_name}'] = data[list_name].apply(skew)\n","    if base[5]:\n","        features_name += [f'skew_{list_name}']\n","\n","    data[f'max_sub_min_{list_name}'] = data[list_name].apply(lambda x: np.max(x) - np.min(x))\n","    if base[6]:\n","        features_name += [f'max_sub_min_{list_name}']\n","\n","    return data, features_name"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"HWHCE4VhsnoI"},"outputs":[],"source":["def extract_features(data, bases=None):\n","    \"\"\"\n","    Extract features from data.\n","    :param data: Dataset of time windows.\n","    :param bases: Dictionary with values of bool lists of size 7 and keys of the names of the vectors to extract\n","    features from\n","    :return: new dataset with extracted features, training feature name list\n","    \"\"\"\n","\n","    if bases is None:\n","        bases = DEFAULT_TRUE_DICT\n","\n","    features_name = []\n","    data['RSSI_diffs'] = data.RSSI.apply(lambda x: x[1:] - x[:-1])\n","    data['RSSI_diffs_abs'] = data.RSSI.apply(lambda x: abs(x[1:] - x[:-1]))\n","    data['RSSI_median_dist'] = data.RSSI.apply(lambda x: abs(x - np.median(x)))\n","\n","    data, features_name = extract_list_feats('RSSI', data, features_name, base=bases['RSSI'])\n","    data, features_name = extract_list_feats('RSSI_diffs', data, features_name, base=bases['RSSI_diffs'])\n","    data, features_name = extract_list_feats('RSSI_diffs_abs', data, features_name, base=bases['RSSI_diffs_abs'])\n","    data, features_name = extract_list_feats('RSSI_median_dist', data, features_name, base=bases['RSSI_median_dist'])\n","\n","    data['max_count_same_value_RSSI'] = data.RSSI.apply(lambda x: np.max(np.unique(x, return_counts=True)[1]))\n","    features_name += ['max_count_same_value_RSSI']\n","\n","    data['RSSI_peaks'] = data.RSSI.apply(lambda x: len(find_peaks(x)[0]))\n","    features_name += ['RSSI_peaks']\n","\n","    data['RSSI_diffs_peaks'] = data.RSSI_diffs.apply(lambda x: len(find_peaks(x)[0]))\n","    features_name += ['RSSI_diffs_peaks']\n","\n","    data['peak_ratio_diffs_RSSI'] = data.apply(\n","        lambda x: x['RSSI_diffs_peaks'] / x['RSSI_peaks'] if x['RSSI_peaks'] > 0 else 0, axis=1)\n","    features_name += ['peak_ratio_diffs_RSSI']\n","\n","    data['RSSI_values_count'] = data.RSSI.apply(lambda x: len(np.unique(x)))\n","    features_name += ['RSSI_values_count']\n","\n","    return data, features_name"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"9d1LWkYFspdV"},"outputs":[],"source":["def window(full_signal: np.ndarray, size: int = 360, stride: int = 360):\n","    \"\"\"\n","    Take a long vector of signals and creates time windows of size \"size\" and stride of size \"stride\"\n","    :param full_signal: the signal to make time windows from\n","    :param size: size of each time window\n","    :param stride: time window stride (step size). When window size <= stride it's mean that there is not overlap between the windows.\n","    :return: time windows of the signal\n","    \"\"\"\n","    return np.lib.stride_tricks.sliding_window_view(full_signal, size)[0::stride]"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"SvXqC9desq6u"},"outputs":[],"source":["def make_data(X, y, window_size: int = 360, stride: int = 360):\n","    \"\"\"\n","    Make data for training a model: making windows, adding metadata information to the time windows dataframe, removing\n","    windows with change in Num_People\n","    :param X: the data.\n","    :param y: the labels\n","    :param window_size: size of each time window\n","    :param stride: time window stride (step size). When window size <= stride it's mean that there is not overlap between the windows.\n","    :return: windowed RSSI DataFrame , labels dataframe\n","    \"\"\"\n","    \n","    X['Num_People'] = y\n","    multi_vals = X.groupby(['Device_ID']).apply(lambda x: x.nunique() == 1).all()\n","    single_vals = list(multi_vals[multi_vals].index)\n","    multi_vals = list(multi_vals[~multi_vals].index)\n","    windows_df = X.groupby(['Device_ID']).RSSI.apply(\n","        lambda x: window(x.values, window_size, stride)).explode().to_frame().reset_index()\n","    for col in (multi_vals + single_vals):\n","        windows_df[col] = X.groupby(['Device_ID'])[col].apply(\n","            lambda x: window(x.values, window_size, stride)).explode().reset_index(drop=True).values\n","    for col in single_vals:\n","        windows_df[col] = windows_df[col].apply(lambda x: x[0])\n","    \n","    df = windows_df\n","    df['change'] = df.Num_People.apply(lambda x: (len(np.unique(x)) > 1))\n","    dfx = df[~df['change']]\n","    df = dfx.copy()\n","    df.Num_People = df.Num_People.apply(lambda x: x[0])\n","    df.drop(columns='change', inplace=True)\n","    return df.drop(columns='Num_People'), df.Num_People"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"wXV3hdypQ9fP"},"outputs":[],"source":["def pre_data(data, RSSI_value_selection, window_size, stride):\n","    \"\"\"\n","    Full preprocessing of the data - train_x, train_y split, feature extraction,\n","    remove data that is smaller than the selected size window, etc.\n","    :param data: the row data.\n","    :param RSSI_value_selection: Which signal values to use.\n","    :param window_size: size of each time window\n","    :param stride: time window stride (step size). When window size <= stride it's mean that there is not overlap between the windows.\n","    :return: train set x (with extracted features per window), train set y\n","    \"\"\"\n","    if RSSI_value_selection==\"RSSI_Left\":\n","        data[\"RSSI\"] = data.RSSI_Left\n","    elif RSSI_value_selection==\"RSSI_Right\":\n","        data[\"RSSI\"] = data.RSSI_Right\n","    elif RSSI_value_selection==\"Min\":\n","        data[\"RSSI\"] = data[['RSSI_Left','RSSI_Right']].min(axis=1).values\n","    elif RSSI_value_selection==\"Max\":\n","        data[\"RSSI\"] = data[['RSSI_Left','RSSI_Right']].max(axis=1).values\n","    else: \n","        data[\"RSSI\"] = np.ceil(data[['RSSI_Left','RSSI_Right']].mean(axis=1).values).astype('int')\n","\n","    data.drop(['Room_Num'], axis=1, inplace=True)\n","    data.dropna(subset = [\"Num_People\"], inplace=True)\n","\n","    for dev_id in list(set(data.Device_ID)):\n","        sub_dev_id = data.loc[data.Device_ID == dev_id]\n","        if len(sub_dev_id) < window_size:\n","            data = data[data.Device_ID != dev_id]\n","    train_x, train_y, raw_x = create_features(data, window_size, stride)\n","    train_x= train_x.reset_index(drop = True)\n","    train_y= train_y.reset_index(drop = True)\n","    train_x.drop('Device_ID', axis=1, inplace=True)\n","    return train_x, train_y, raw_x"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"GV7thotYs2xb"},"outputs":[],"source":["def create_features(data, window_size, stride):\n","    \"\"\"\n","    Feature engineering: \n","    :param data: the data\n","    :param window_size: size of each time window\n","    :param stride: time window stride (step size). When window size <= stride it's mean that there is not overlap between the windows.\n","    :return: full dataset (with extracted features), train set y\n","    \"\"\"\n","\n","    X, y = data.drop(columns='Num_People'), data['Num_People']\n","    X, y = make_data(X, y, window_size=window_size, stride=stride)\n","    X_features, train_feat = extract_features(X.copy())\n","    train_feat.append('Device_ID')\n","    X_features = X_features[train_feat]\n","    return X_features, y, X"]},{"cell_type":"markdown","metadata":{"id":"jEqAImFKtLAI"},"source":["#**Model**"]},{"cell_type":"markdown","metadata":{"id":"_xCScgzotOeS"},"source":["##**Data preparation**\n"]},{"cell_type":"markdown","metadata":{"id":"upQJWHKQZ05F"},"source":["Download training data"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3061,"status":"ok","timestamp":1651992579027,"user":{"displayName":"Neta Mor","userId":"10332383750038914870"},"user_tz":-180},"id":"Qsp1RMBjQBti","outputId":"6a110a15-3bcb-4269-f9b9-13c423a6770d"},"outputs":[],"source":["# !gdown -O ../data/mafat_wifi_challenge_training_set_v1.csv 'https://drive.google.com/uc?id=121CbFZbU6kAWNjmjZF232DsiGF2-BoYy'"]},{"cell_type":"markdown","metadata":{"id":"FVvxc4EnZ7Xj"},"source":["Read traning data to dataframe"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"n0DAa_suZ6YL"},"outputs":[],"source":["data = pd.read_csv('../data/mafat_wifi_challenge_training_set_v1.csv')"]},{"cell_type":"markdown","metadata":{"id":"Hjyqbul04SnO"},"source":["window_size - defines the number of timestamps in each window\n","\n","window_stride - defines the shift between windows, i.e., for window_size = 360 and window_stride = 1: timestamps 0 - 359 will be selected for the first window and timestamps 1-360 will be selected for the second window. And so on for the rest of the windows for each device."]},{"cell_type":"code","execution_count":10,"metadata":{"cellView":"form","id":"mRWCHSRxtQBr"},"outputs":[],"source":["window_size = 360 #@param {type:\"integer\"}\n","window_stride = 360 #@param {type:\"integer\"}"]},{"cell_type":"markdown","metadata":{"id":"uYmVMMuW5fgc"},"source":["Select the signal values to do the feature - engineering (\"extract_feature\" function): RSSI_Left/ RSSI_Right/ the minimum value ​​between the signals/ The maximum value ​​between the signals/ average of signals"]},{"cell_type":"code","execution_count":11,"metadata":{"cellView":"form","id":"ndOqSAT9_Scn"},"outputs":[],"source":["RSSI_value_selection = \"Average\" #@param [\"RSSI_Left\",\"RSSI_Right\",\"Min\",\"Max\",\"Average\"]"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"d1zEVoB-sjtj"},"outputs":[],"source":["\"\"\"\n","Lists of features to extract from each vector\n","\"\"\"\n","\n","DEFAULT_TRUE_LIST = [True] * 7\n","DEFAULT_TRUE_DICT = {\n","    'RSSI': [True, False, False, False, True, True, True],\n","    'RSSI_diffs': [True, True, True, False, True, True, True],\n","    'RSSI_diffs_abs': [False, False, True, True, True, False, True],\n","    'RSSI_median_dist': [True, False, True, True, True, False, True]\n","}"]},{"cell_type":"markdown","metadata":{"id":"r1J90-No6hSl"},"source":["Preprocess training data"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"KWSUsiGTRRDc"},"outputs":[],"source":["data_train_x, data_train_y, raw_x = pre_data(data, RSSI_value_selection, window_size, window_stride)"]},{"cell_type":"markdown","metadata":{"id":"M-dAePFZmfrq"},"source":["##**Train RandomForestClassifier model**"]},{"cell_type":"markdown","metadata":{"id":"KF-8i9SPqJmo"},"source":["###**Track 1**"]},{"cell_type":"markdown","metadata":{"id":"zrtpL4fD9LmH"},"source":["####**Convert classes to 0/1**"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"EUXvEoOGVmMQ"},"outputs":[],"source":["# Convert classes to 0/1 to evaluate the model's score for predicting room occupancy\n","# in Track 1 you are required to predict probability for room occupancy (in the range of 0-1).\n","# however, the data is used for both tracks, and it contains the raw number of people\n","# in the room, here we convert the raw data to 0 or 1.\n","\n","data_train_track1 = data_train_y.copy()\n","data_train_track1.loc[data_train_y>0] = 1"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["data_train_x['y_track1'] = data_train_track1"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["data_train_x['y_track2'] = data_train_y"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["data_train_x.to_csv(\"processed_rows.csv\", index=False)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["import csv\n","a=raw_x[:]['RSSI']#.to_csv(\"raw_rows.csv\", index=False)\n","b=pd.DataFrame(a.to_list())\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pd.concat([b, data_train_x['y_track1'], data_train_x['y_track2']], axis=1)"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["df.to_csv(\"raw_rows.csv\", index=False)"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["df.drop(['y_track1', 'y_track2'], axis=1, inplace=True)"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["df_combined = pd.concat([df, data_train_x], axis=1)"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["df_combined.to_csv(\"combined_rows.csv\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"QtuMMC1V9bAD"},"source":["####**Fit Random Forest estimator to all training set**\n","#### No train-validation split is used (we use the submission as validation)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2882,"status":"ok","timestamp":1651992617989,"user":{"displayName":"Neta Mor","userId":"10332383750038914870"},"user_tz":-180},"id":"_0Qofum3TWY0","outputId":"9c84ea2f-3ccd-4c4f-b20f-1a8c3f3554a4"},"outputs":[],"source":["#Train the model on all training data and calculate the AUC metric for the first track\n","rfc  = RandomForestClassifier(max_depth=5, min_samples_leaf=2, min_samples_split=2,\n","                              n_estimators=350, random_state=0, class_weight=\"balanced\", bootstrap = True)\n","\n","rfc.fit(data_train_x, data_train_track1)\n","\n","train_predict_classification = rfc.predict(data_train_x)\n","print(f'The auc for all training set: {round(roc_auc_score(data_train_track1, rfc.predict_proba(data_train_x)[:,1], average= None),3)}')"]},{"cell_type":"markdown","metadata":{"id":"fq23wrI4grOd"},"source":["####**Save model - track 1**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ES07rfsugzox"},"outputs":[],"source":["# save model weights\n","filename = \"model_track_1.sav\"\n","pickle.dump(rfc, open(filename, 'wb'))"]},{"cell_type":"markdown","metadata":{"id":"XnUxsnYXPdt4"},"source":["##**Prepare submmision**"]},{"cell_type":"markdown","metadata":{"id":"Yv1xTHrLM57V"},"source":["**Attention!**\n","\n","Full submission includes the following files in a zip archive:\n","1.   model.py (**must**) - contains a class named \"model\". The class must have implementations of \"load\", \"__init__\" and \"predict\" functions:\n","    *    __init__ - initialization function of the model class.\n","    *   load - a function that loads the model and model weights.\n","    *   predict - a function that receives one window each time (as a DataFrame) and returns a one value prediction.\n","    * **The file may contain other functions (within the class or outside of it)**\n","    * imports used by the class must be compatible with the permitted python packages.\n","\n","\n","2. metadata (**must**)\n","    * contain the command for running the model file - **do not change this file**\n","\n","\n","3.   model weights (**optional**)\n","    * in this example, we demonstrate how to save a Random Forest classifier   weights. however, these can be any kind of weights as long as they are compatible with the model and the permitted python packages. \n","    * if the model depends on these weights, this file is mandatory.  \n","\n","\n","4. Helper_func.py (**optional**)\n","    * This file contains helper functions. The file can have a different name as long as it is compatible with model.py\n","    * if the model depends on these weights, this file is mandatory.  \n"]},{"cell_type":"markdown","metadata":{"id":"xLxA33uIAN6W"},"source":["Running the following cells will generate a zip file with a valid submission for track 1.\n","\n","Notice the minor changes that can be made to make it a valid submission for track 2 .\n","\n","This is the baseline submission, you can check it's score on the leaderboard."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":301,"status":"ok","timestamp":1651992624443,"user":{"displayName":"Neta Mor","userId":"10332383750038914870"},"user_tz":-180},"id":"Syc8cu9cQvn3","outputId":"41624e32-d77b-42cd-9e2a-195e26cb3a49"},"outputs":[],"source":["%%writefile helper_func.py\n","import numpy as np   \n","import pandas as pd\n","from scipy.stats import skew\n","from scipy.signal import find_peaks\n","\n","def extract_features(X, bases=None):\n","    \"\"\"\n","    Extract features from data.\n","    :param X: Dataset of time windows.\n","    :param bases: Dictionary with values of bool lists of size 7 and keys of the names of the vectors to extract\n","    features from\n","    :return: new dataset with extracted features, training feature name list\n","    \"\"\"\n","    # Restructure dataframe to fit preprocessing features extraction functions - changing the dataframe to have one row.\n","    # Each column is compressed to a list.\n","    data = pd.DataFrame(columns=X.columns)\n","    for col in data.columns:\n","        data.loc[0,col]= np.array(X[col])\n","\n","    if bases is None:\n","        bases = {\n","        'RSSI': [True, False, False, False, True, True, True],\n","        'RSSI_diffs': [True, True, True, False, True, True, True],\n","        'RSSI_diffs_abs': [False, False, True, True, True, False, True],\n","        'RSSI_median_dist': [True, False, True, True, True, False, True]\n","    } \n","\n","    features_name = []\n","    data['RSSI_diffs'] = data.RSSI.apply(lambda x: x[1:] - x[:-1])\n","    data['RSSI_diffs_abs'] = data.RSSI.apply(lambda x: abs(x[1:] - x[:-1]))\n","    data['RSSI_median_dist'] = data.RSSI.apply(lambda x: abs(x - np.median(x)))\n","\n","    data, features_name = extract_list_feats('RSSI', data, features_name, base=bases['RSSI'])\n","    data, features_name = extract_list_feats('RSSI_diffs', data, features_name, base=bases['RSSI_diffs'])\n","    data, features_name = extract_list_feats('RSSI_diffs_abs', data, features_name, base=bases['RSSI_diffs_abs'])\n","    data, features_name = extract_list_feats('RSSI_median_dist', data, features_name, base=bases['RSSI_median_dist'])\n","\n","    data['max_count_same_value_RSSI'] = data.RSSI.apply(lambda x: np.max(np.unique(x, return_counts=True)[1]))\n","    features_name += ['max_count_same_value_RSSI']\n","\n","    data['RSSI_peaks'] = data.RSSI.apply(lambda x: len(find_peaks(x)[0]))\n","    features_name += ['RSSI_peaks']\n","\n","    data['RSSI_diffs_peaks'] = data.RSSI_diffs.apply(lambda x: len(find_peaks(x)[0]))\n","    features_name += ['RSSI_diffs_peaks']\n","\n","    data['peak_ratio_diffs_RSSI'] = data.apply(\n","        lambda x: x['RSSI_diffs_peaks'] / x['RSSI_peaks'] if x['RSSI_peaks'] > 0 else 0, axis=1)\n","    features_name += ['peak_ratio_diffs_RSSI']\n","\n","    data['RSSI_values_count'] = data.RSSI.apply(lambda x: len(np.unique(x)))\n","    features_name += ['RSSI_values_count']\n","\n","    return data, features_name\n","\n","def extract_list_feats(list_name: str, data, features_name: list, base=None):\n","    \"\"\"\n","    Extract Features from vector.\n","    :param list_name: Vector to extract features from.\n","    :param data: Dataset to extract features from.\n","    :param features_name: Feature list to add new feature names to.\n","    :param base: Disable the use of features.\n","    :return: Data with features, updated feature name list.\n","    \"\"\"\n","\n","    if base is None:\n","        base = DEFAULT_TRUE_LIST\n","\n","    data[f'max_{list_name}'] = data[list_name].apply(np.max)\n","    if base[0]:\n","        features_name += [f'max_{list_name}']\n","\n","    data[f'min_{list_name}'] = data[list_name].apply(np.min)\n","    if base[1]:\n","        features_name += [f'min_{list_name}']\n","\n","    data[f'mean_{list_name}'] = data[list_name].apply(np.mean)\n","    if base[2]:\n","        features_name += [f'mean_{list_name}']\n","\n","    data[f'median_{list_name}'] = data[list_name].apply(np.median)\n","    if base[3]:\n","        features_name += [f'median_{list_name}']\n","\n","    data[f'std_{list_name}'] = data[list_name].apply(np.std)\n","    if base[4]:\n","        features_name += [f'std_{list_name}']\n","\n","    data[f'skew_{list_name}'] = data[list_name].apply(skew)\n","    if base[5]:\n","        features_name += [f'skew_{list_name}']\n","\n","    data[f'max_sub_min_{list_name}'] = data[list_name].apply(lambda x: np.max(x) - np.min(x))\n","    if base[6]:\n","        features_name += [f'max_sub_min_{list_name}']\n","\n","    return data, features_name\n","    \n","def preprocess(X, RSSI_value_selection):\n","    \"\"\"\n","    Calculate the features on the selected RSSI on the test set\n","    :param X: Dataset to extract features from.\n","    :param RSSI_value_selection: Which signal values to use- - in our case it is Average.\n","    :return: Test x dataset with features\n","    \"\"\"\n","    if RSSI_value_selection==\"RSSI_Left\":\n","        X[\"RSSI\"] = X.RSSI_Left\n","    elif RSSI_value_selection==\"RSSI_Right\":\n","        X[\"RSSI\"] = X.RSSI_Right\n","    elif RSSI_value_selection==\"Min\":\n","        X[\"RSSI\"] = X[['RSSI_Left','RSSI_Right']].min(axis=1).values\n","    elif RSSI_value_selection==\"Max\":\n","        X[\"RSSI\"] = X[['RSSI_Left','RSSI_Right']].max(axis=1).values\n","    else: \n","        X[\"RSSI\"] = np.ceil(X[['RSSI_Left','RSSI_Right']].mean(axis=1).values).astype('int')\n","\n","    X, features_name = extract_features(X)\n","    X.drop('Device_ID', axis=1, inplace=True)\n","    return X[features_name]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":294,"status":"ok","timestamp":1651992628284,"user":{"displayName":"Neta Mor","userId":"10332383750038914870"},"user_tz":-180},"id":"vw-PM_2UPr6w","outputId":"10198c5c-7161-4153-a693-dfe38c0503d2"},"outputs":[],"source":["%%writefile model.py\n","\n","import pickle\n","import numpy as np\n","from os.path import isfile\n","import joblib\n","from sklearn.ensemble import RandomForestClassifier\n","from helper_func import preprocess\n","import os\n","\n","class model:\n","    def __init__(self):\n","        '''\n","        Init the model\n","        '''\n","\n","        self.model  = RandomForestClassifier(max_depth=5, min_samples_leaf=2, min_samples_split=2,\n","                              n_estimators=350, random_state=0, class_weight=\"balanced\", bootstrap = True)\n","        self.RSSI_value_selection = 'Average'\n","\n","    def predict(self, X):\n","        '''\n","        Edit this function to fit your model.\n","\n","        This function should provide predictions of labels on (test) data.\n","        Make sure that the predicted values are in the correct format for the scoring\n","        metric.\n","        preprocess: it our code for add feature to the data before we predict the model.\n","        :param X: is DataFrame with the columns - 'Time', 'Device_ID', 'Rssi_Left','Rssi_Right'. \n","                  X is window of size 360 samples time, shape(360,4).\n","        :return: a float value of the prediction for class 1 (the room is occupied).\n","        '''\n","        # preprocessing should work on a single window, i.e a dataframe with 360 rows and 4 columns\n","        X = preprocess(X,self.RSSI_value_selection)\n","        y = self.model.predict_proba(X)[:,1][0]\n","        \n","        '''\n","        Track 2 - for track 2 we naively assume that the model from track-1 predicts 0/1 correctly. \n","        We use that assumption in the following way:\n","        when the room is occupied (1,2,3 - model predicted 1) we assign the majorty class (2) as prediction.       \n","        '''\n","        #y = 0 if y<0.5 else 2\n","        return y\n","\n","    def load(self, dir_path):\n","        '''\n","        Edit this function to fit your model.\n","\n","        This function should load the model that you trained on the train set.\n","        :param dir_path: A path for the folder the model is submitted \n","        '''\n","        model_name = 'model_track_1.sav' \n","        model_file = os.path.join(dir_path, model_name)\n","        self.model = joblib.load(model_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":290,"status":"ok","timestamp":1651992630327,"user":{"displayName":"Neta Mor","userId":"10332383750038914870"},"user_tz":-180},"id":"hgJin7htSDYd","outputId":"7a005825-28ee-4747-a5a0-ced2b3cfcc14"},"outputs":[],"source":["%%writefile metadata\n","command: python3 $program/model.py $input $output"]},{"cell_type":"markdown","metadata":{"id":"9zneCTizc6ah"},"source":["zip the files to submit"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":408,"status":"ok","timestamp":1651992631790,"user":{"displayName":"Neta Mor","userId":"10332383750038914870"},"user_tz":-180},"id":"fLoc-RbhTEkc","outputId":"cc1d605b-3f4f-40ce-a999-c7c9014b14d2"},"outputs":[],"source":["!zip -r submission.zip model.py helper_func.py metadata model_track_1.sav"]},{"cell_type":"markdown","metadata":{"id":"NXZd3JF1lUKz"},"source":["*You can use this notebook to save your file, download it, and submit it on CodaLab.\n","\n","To download the zip file, use the file manager panel.\n","Use View > Table of contents to show the sidebar then click the Files tab. Right-click the file and select Download."]},{"cell_type":"markdown","metadata":{"id":"QLubP8vnT4rF"},"source":["##**Example- Prediction with the submitted model**"]},{"cell_type":"markdown","metadata":{"id":"_MHkJa0tqQ2Y"},"source":["In this section, we demonstrate how to predict with the submitted model  on window (360 samples)."]},{"cell_type":"markdown","metadata":{"id":"M1DNt-CtZNRF"},"source":["###download and read one window for prediction"]},{"cell_type":"markdown","metadata":{"id":"wgyi3hSir0JV"},"source":["(An example is based on the train set)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":965,"status":"ok","timestamp":1651992636032,"user":{"displayName":"Neta Mor","userId":"10332383750038914870"},"user_tz":-180},"id":"hTIjC2T8UaAH","outputId":"21cd5705-cc57-4d23-9ac5-68987a490a19"},"outputs":[],"source":["!gdown -O one_window_for_demo.csv https://drive.google.com/uc?id=1kVAMV-zEn2bGLLtMOYA7-gVLnofCo3m_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oR5sqqGuU1C_"},"outputs":[],"source":["X = pd.read_csv('/content/one_window_for_demo.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1651992638487,"user":{"displayName":"Neta Mor","userId":"10332383750038914870"},"user_tz":-180},"id":"t6OHtM8TXqHN","outputId":"8ecf0567-7cbd-4ba2-89b8-df6cf84c0cb7"},"outputs":[],"source":["print(X.head(10))\n","print(f'window shape: {len(X)}')"]},{"cell_type":"markdown","metadata":{"id":"AqLndlT9qoZp"},"source":["###Create object model, load and predict"]},{"cell_type":"markdown","metadata":{"id":"wRG9AMNneIHL"},"source":["Unzip the submission files"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":294,"status":"ok","timestamp":1651992640350,"user":{"displayName":"Neta Mor","userId":"10332383750038914870"},"user_tz":-180},"id":"qTO_6VDbZmN0","outputId":"69bbbc37-26b4-4a87-88dc-a19ee9ad106c"},"outputs":[],"source":["!unzip -o '/content/submission.zip'"]},{"cell_type":"markdown","metadata":{"id":"zsB_FxhBehpT"},"source":["Create model object, load and predict"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":429,"status":"ok","timestamp":1651992641894,"user":{"displayName":"Neta Mor","userId":"10332383750038914870"},"user_tz":-180},"id":"mpy1sxMMY-O2","outputId":"62241fc1-b56b-4f58-826b-943d6898e566"},"outputs":[],"source":["from model import *\n","M = model()\n","M.load('')\n","Y_test=[]\n","unique_windows = list(set(X.Num_Window))\n","for window in unique_windows:\n","   X_test_window = X.loc[X['Num_Window'] == window]\n","   X_test_window.drop('Num_Window', axis=1, inplace=True)\n","   Y_test.append(M.predict(X_test_window))\n","\n","print(f'Occupancy prediction: {round(Y_test[0],3)}')"]}],"metadata":{"colab":{"collapsed_sections":["AuMYqFGBrGv_","M1DNt-CtZNRF","AqLndlT9qoZp"],"name":"mafat_wifi_challenge_baseline_model.ipynb","provenance":[]},"interpreter":{"hash":"395fc3e709e5aff7d0aef6aefeaea45f9dbc19bd6c0a95b346ef5f3954bfe4bb"},"kernelspec":{"display_name":"Python 3.10.4 ('mafat')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}
